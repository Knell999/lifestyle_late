"""
Model selection and training components
"""

import streamlit as st
import pandas as pd
import numpy as np
from typing import Dict, Any, Optional
import sys
import os
import time

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

def create_model_training_section(config: Dict[str, Any]):
    """Create model training interface"""
    st.title("ğŸ¯ ëª¨ë¸ í›ˆë ¨")
    
    # Check if data is available
    if 'data' not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì—…ë¡œë“œ' í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return
    
    df = st.session_state.data
    
    # Training configuration
    st.markdown("### âš™ï¸ í›ˆë ¨ ì„¤ì •")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info(f"**ì„ íƒëœ ëª¨ë¸**\n{', '.join(config['models'])}")
    
    with col2:
        st.info(f"**ë°ì´í„° ëª¨ë“œ**\n{config['data_mode']}")
    
    with col3:
        st.info(f"**CV Folds**\n{config['cv_folds']}")
    
    # Advanced settings display
    with st.expander("ğŸ”§ ì„¸ë¶€ ì„¤ì •"):
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨**: {config['test_size']}")
            st.write(f"**Random State**: {config['random_state']}")
        with col2:
            st.write(f"**ì´ ë°ì´í„° í¬ê¸°**: {len(df):,} í–‰")
            st.write(f"**í›ˆë ¨ ë°ì´í„° ì˜ˆìƒ**: {int(len(df) * (1 - config['test_size'])):,} í–‰")
    
    # Start training button
    if st.button("ğŸš€ ëª¨ë¸ í›ˆë ¨ ì‹œì‘", type="primary", use_container_width=True):
        train_models(df, config)

def train_models(df: pd.DataFrame, config: Dict[str, Any]):
    """Train models with progress tracking"""
    try:
        # Import required modules
        from pipeline import MLPipeline
        from config import TARGET_COLUMN
        
        # Create progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Initialize pipeline
        status_text.text("ğŸ”§ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
        progress_bar.progress(10)
        
        pipeline = MLPipeline(
            target_column=TARGET_COLUMN,
            test_size=config['test_size'],
            random_state=int(config['random_state']),
            cv_folds=config['cv_folds']
        )
        
        # Load and preprocess data
        status_text.text("ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        progress_bar.progress(30)
        
        results = pipeline.run_pipeline(
            data=df,
            mode=config['data_mode'].lower(),
            models_to_train=config['models']
        )
        
        progress_bar.progress(100)
        status_text.text("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        
        # Store results in session state
        st.session_state.training_results = results
        st.session_state.trained_pipeline = pipeline
        
        # Display results
        display_training_results(results)
        
    except Exception as e:
        st.error(f"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def display_training_results(results: Dict[str, Any]):
    """Display training results"""
    st.markdown("### ğŸ“Š í›ˆë ¨ ê²°ê³¼")
    
    if 'model_results' in results:
        # Model performance comparison
        st.markdown("#### ğŸ† ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
        
        performance_data = []
        for model_name, model_result in results['model_results'].items():
            performance_data.append({
                'ëª¨ë¸': model_name,
                'ì •í™•ë„': f"{model_result.get('accuracy', 0):.4f}",
                'F1-Score': f"{model_result.get('f1_score', 0):.4f}",
                'ROC-AUC': f"{model_result.get('roc_auc', 0):.4f}",
                'CV í‰ê· ': f"{model_result.get('cv_scores', [0])[0] if model_result.get('cv_scores') else 0:.4f}"
            })
        
        performance_df = pd.DataFrame(performance_data)
        st.dataframe(performance_df, use_container_width=True)
        
        # Best model highlight
        if performance_data:
            best_model = max(performance_data, key=lambda x: float(x['ì •í™•ë„']))
            st.success(f"ğŸ¯ **ìµœê³  ì„±ëŠ¥ ëª¨ë¸**: {best_model['ëª¨ë¸']} (ì •í™•ë„: {best_model['ì •í™•ë„']})")
    
    # Feature importance (if available)
    if 'feature_importance' in results:
        st.markdown("#### ğŸ“ˆ íŠ¹ì„± ì¤‘ìš”ë„")
        
        importance_df = pd.DataFrame(results['feature_importance'])
        if not importance_df.empty:
            # Display top 10 features
            top_features = importance_df.head(10)
            st.bar_chart(top_features.set_index('feature')['importance'])
            
            with st.expander("ì „ì²´ íŠ¹ì„± ì¤‘ìš”ë„ ë³´ê¸°"):
                st.dataframe(importance_df, use_container_width=True)

def create_prediction_section(config: Dict[str, Any]):
    """Create prediction interface"""
    st.title("ğŸ”® ì˜ˆì¸¡")
    
    # Check if model is trained
    if 'trained_pipeline' not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € 'ëª¨ë¸ í›ˆë ¨' í˜ì´ì§€ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ì„¸ìš”.")
        return
    
    pipeline = st.session_state.trained_pipeline
    
    # Prediction options
    st.markdown("### ğŸ“ ì˜ˆì¸¡ ë°©ë²• ì„ íƒ")
    
    prediction_mode = st.radio(
        "ì˜ˆì¸¡ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:",
        ["ê°œë³„ ê³ ê° ì˜ˆì¸¡", "ë°°ì¹˜ ì˜ˆì¸¡"],
        horizontal=True
    )
    
    if prediction_mode == "ê°œë³„ ê³ ê° ì˜ˆì¸¡":
        create_individual_prediction(pipeline)
    else:
        create_batch_prediction(pipeline)

def create_individual_prediction(pipeline):
    """Create individual customer prediction interface"""
    st.markdown("#### ğŸ‘¤ ê°œë³„ ê³ ê° ì •ë³´ ì…ë ¥")
    
    # Get feature names from the pipeline
    try:
        from config import ONEHOT_FEATURES, LABEL_FEATURES, BINARY_FEATURES
        
        # Create input form
        with st.form("individual_prediction"):
            col1, col2 = st.columns(2)
            
            user_input = {}
            
            with col1:
                st.markdown("**ê°œì¸ ì •ë³´**")
                # Example inputs - you'll need to customize based on your actual features
                user_input['AGE'] = st.selectbox("ì—°ë ¹ëŒ€", ["20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€+"])
                user_input['SEX'] = st.selectbox("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±"])
                user_input['JB_TP'] = st.selectbox("ì§ì—…", ["íšŒì‚¬ì›", "ìì˜ì—…", "ê³µë¬´ì›", "ê¸°íƒ€"])
                
            with col2:
                st.markdown("**ë¼ì´í”„ìŠ¤íƒ€ì¼**")
                user_input['CAR_YN'] = st.selectbox("ì°¨ëŸ‰ ë³´ìœ ", ["Y", "N"])
                user_input['VIP_CARD_YN'] = st.selectbox("VIP ì¹´ë“œ", ["Y", "N"])
                user_input['TRAVEL_OS'] = st.selectbox("í•´ì™¸ì—¬í–‰", ["Y", "N"])
            
            submitted = st.form_submit_button("ğŸ”® ì˜ˆì¸¡í•˜ê¸°", type="primary")
            
            if submitted:
                # Convert input to dataframe
                input_df = pd.DataFrame([user_input])
                
                # Make prediction
                try:
                    # This would need to be implemented in your pipeline
                    st.info("ê°œë³„ ì˜ˆì¸¡ ê¸°ëŠ¥ì€ íŒŒì´í”„ë¼ì¸ì— ì¶”ê°€ êµ¬í˜„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    
                    # Placeholder for prediction result
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì˜ˆì¸¡ ë“±ê¸‰", "A")
                    with col2:
                        st.metric("ì‹ ë¢°ë„", "85.2%")
                    with col3:
                        st.metric("ìœ„í—˜ë„", "ë‚®ìŒ")
                
                except Exception as e:
                    st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def create_batch_prediction(pipeline):
    """Create batch prediction interface"""
    st.markdown("#### ğŸ“„ ë°°ì¹˜ ì˜ˆì¸¡")
    
    # File upload for batch prediction
    uploaded_file = st.file_uploader(
        "ì˜ˆì¸¡í•  ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (CSV)",
        type=['csv'],
        help="ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ê³ ê° ë°ì´í„°ê°€ í¬í•¨ëœ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    if uploaded_file is not None:
        try:
            batch_df = pd.read_csv(uploaded_file)
            st.success(f"âœ… íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤! ({len(batch_df):,}ê°œ í–‰)")
            
            # Display data preview
            st.markdown("##### ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(batch_df.head(), use_container_width=True)
            
            # Predict button
            if st.button("ğŸ”® ë°°ì¹˜ ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
                with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
                    # Placeholder for batch prediction
                    st.info("ë°°ì¹˜ ì˜ˆì¸¡ ê¸°ëŠ¥ì€ íŒŒì´í”„ë¼ì¸ì— ì¶”ê°€ êµ¬í˜„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    
                    # Mock prediction results
                    batch_df['predicted_grade'] = np.random.choice(['A', 'B', 'C', 'D'], len(batch_df))
                    batch_df['confidence'] = np.random.uniform(0.7, 0.95, len(batch_df))
                    
                    st.markdown("##### ğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼")
                    st.dataframe(batch_df, use_container_width=True)
                    
                    # Download results
                    csv = batch_df.to_csv(index=False)
                    st.download_button(
                        label="ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                        data=csv,
                        file_name="prediction_results.csv",
                        mime="text/csv"
                    )
            
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    else:
        st.info("ğŸ‘† ì˜ˆì¸¡í•  ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
