"""
Data upload and preprocessing components
"""

import streamlit as st
import pandas as pd
import numpy as np
from typing import Optional
import sys
import os

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

def create_data_upload_section():
    """Create data upload and exploration section"""
    st.title("ğŸ“‚ ë°ì´í„° ì—…ë¡œë“œ ë° íƒìƒ‰")
    
    # File upload
    st.markdown("### ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "CSV íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['csv'],
        help="KCB ë“±ê¸‰ ì˜ˆì¸¡ì— í•„ìš”í•œ ë°ì´í„°ê°€ í¬í•¨ëœ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    # Load default data if no file uploaded
    use_default = st.checkbox("ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©", help="í”„ë¡œì íŠ¸ì— í¬í•¨ëœ ê¸°ë³¸ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤")
    
    df = None
    
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            st.success(f"âœ… íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤! ({len(df):,}ê°œ í–‰, {len(df.columns)}ê°œ ì—´)")
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            return None
    
    elif use_default:
        try:
            # Import config with proper path handling
            try:
                from src.config import DATA_PATH
            except ImportError:
                # Fallback to relative path
                import sys
                import os
                sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))
                from src.config import DATA_PATH
            
            # Try different possible paths for the data file
            possible_paths = [
                DATA_PATH,
                os.path.join('data', 'df_KCB_grade.csv'),
                os.path.join('..', 'data', 'df_KCB_grade.csv'),
                os.path.join(os.path.dirname(__file__), '..', 'data', 'df_KCB_grade.csv')
            ]
            
            df = None
            for path in possible_paths:
                try:
                    if os.path.exists(path):
                        df = pd.read_csv(path)
                        break
                except:
                    continue
            
            if df is not None:
                st.success(f"âœ… ê¸°ë³¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤! ({len(df):,}ê°œ í–‰, {len(df.columns)}ê°œ ì—´)")
            else:
                st.error("âŒ ê¸°ë³¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                return None
        except Exception as e:
            st.error(f"âŒ ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            return None
    
    if df is not None:
        # Store in session state
        st.session_state.data = df
        
        # Data overview
        st.markdown("### ğŸ“Š ë°ì´í„° ê°œìš”")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì´ í–‰ ìˆ˜", f"{len(df):,}")
        with col2:
            st.metric("ì´ ì—´ ìˆ˜", f"{len(df.columns):,}")
        with col3:
            st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", f"{df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
        with col4:
            missing_count = df.isnull().sum().sum()
            st.metric("ê²°ì¸¡ê°’", f"{missing_count:,}")
        
        # Data preview
        st.markdown("### ğŸ‘€ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df.head(10), use_container_width=True)
        
        # Data info tabs
        tab1, tab2, tab3, tab4 = st.tabs(["ê¸°ë³¸ ì •ë³´", "í†µê³„ ìš”ì•½", "ê²°ì¸¡ê°’ ë¶„ì„", "ë°ì´í„° íƒ€ì…"])
        
        with tab1:
            st.markdown("#### ğŸ“‹ ê¸°ë³¸ ì •ë³´")
            buffer = []
            buffer.append(f"ë°ì´í„° í˜•íƒœ: {df.shape}")
            buffer.append(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
            buffer.append(f"ì¤‘ë³µëœ í–‰: {df.duplicated().sum():,}ê°œ")
            
            for info in buffer:
                st.text(info)
        
        with tab2:
            st.markdown("#### ğŸ“ˆ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ í†µê³„ ìš”ì•½")
            numeric_df = df.select_dtypes(include=[np.number])
            if not numeric_df.empty:
                st.dataframe(numeric_df.describe(), use_container_width=True)
            else:
                st.info("ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        with tab3:
            st.markdown("#### â“ ê²°ì¸¡ê°’ ë¶„ì„")
            missing_info = df.isnull().sum()
            missing_percent = (missing_info / len(df)) * 100
            
            missing_df = pd.DataFrame({
                'ì—´ ì´ë¦„': missing_info.index,
                'ê²°ì¸¡ê°’ ê°œìˆ˜': missing_info.values,
                'ê²°ì¸¡ê°’ ë¹„ìœ¨(%)': missing_percent.values
            })
            missing_df = missing_df[missing_df['ê²°ì¸¡ê°’ ê°œìˆ˜'] > 0].sort_values('ê²°ì¸¡ê°’ ê°œìˆ˜', ascending=False)
            
            if not missing_df.empty:
                st.dataframe(missing_df, use_container_width=True)
            else:
                st.success("âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤!")
        
        with tab4:
            st.markdown("#### ğŸ·ï¸ ë°ì´í„° íƒ€ì… ì •ë³´")
            dtype_info = pd.DataFrame({
                'ì—´ ì´ë¦„': df.columns,
                'ë°ì´í„° íƒ€ì…': df.dtypes.values,
                'ê³ ìœ ê°’ ê°œìˆ˜': [df[col].nunique() for col in df.columns],
                'ì˜ˆì‹œ ê°’': [str(df[col].iloc[0]) if not pd.isna(df[col].iloc[0]) else 'NaN' for col in df.columns]
            })
            st.dataframe(dtype_info, use_container_width=True)
        
        # Target variable analysis if available
        try:
            # Import TARGET_COLUMN with proper path handling
            try:
                from src.config import TARGET_COLUMN
            except ImportError:
                # Fallback to relative path
                import sys
                import os
                sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))
                from src.config import TARGET_COLUMN
        except ImportError:
            # If config is not available, use default target column name
            TARGET_COLUMN = "KCB_grade"
        
        if TARGET_COLUMN in df.columns:
            st.markdown("### ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ì„")
            target_dist = df[TARGET_COLUMN].value_counts().sort_index()
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### ğŸ“Š ë“±ê¸‰ ë¶„í¬")
                st.dataframe(
                    pd.DataFrame({
                        'ë“±ê¸‰': target_dist.index,
                        'ê°œìˆ˜': target_dist.values,
                        'ë¹„ìœ¨(%)': (target_dist.values / len(df)) * 100
                    }),
                    use_container_width=True
                )
            
            with col2:
                st.markdown("#### ğŸ“ˆ ë“±ê¸‰ ë¶„í¬ ì°¨íŠ¸")
                st.bar_chart(target_dist)
        
        # Data quality assessment
        st.markdown("### ğŸ” ë°ì´í„° í’ˆì§ˆ í‰ê°€")
        
        quality_checks = []
        
        # Check for duplicates
        duplicates = df.duplicated().sum()
        if duplicates > 0:
            quality_checks.append(f"âš ï¸ ì¤‘ë³µëœ í–‰ì´ {duplicates}ê°œ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            quality_checks.append("âœ… ì¤‘ë³µëœ í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # Check for missing values
        total_missing = df.isnull().sum().sum()
        if total_missing > 0:
            quality_checks.append(f"âš ï¸ ì´ {total_missing}ê°œì˜ ê²°ì¸¡ê°’ì´ ìˆìŠµë‹ˆë‹¤.")
        else:
            quality_checks.append("âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # Check for constant columns
        constant_cols = [col for col in df.columns if df[col].nunique() <= 1]
        if constant_cols:
            quality_checks.append(f"âš ï¸ ìƒìˆ˜ ì—´ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(constant_cols)}")
        else:
            quality_checks.append("âœ… ëª¨ë“  ì—´ì´ ì ì ˆí•œ ë³€ë™ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.")
        
        for check in quality_checks:
            if "âš ï¸" in check:
                st.warning(check)
            else:
                st.success(check)
        
        return df
    
    else:
        st.info("ğŸ‘† ìœ„ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ê¸°ë³¸ ë°ì´í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        return None
